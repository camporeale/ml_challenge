{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.es import Spanish\n",
    "from spacy.lang.pt import Portuguese\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from multiprocessing import  Pool\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import csv\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data_train = pd.read_csv('../data/train.csv',nrows=1000000)\n",
    "data_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.iloc[5341]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hidrolavadora Lavor One 120 Bar 1700w  Bomba Aluminio Italia',\n",
       "       'Placa De Sonido - Behringer Umc22',\n",
       "       'Maquina De Lavar Electrolux 12 Kilos',\n",
       "       'Par Disco De Freio Diant Vent Gol 8v 08/ Fremax Bd5298',\n",
       "       'Flashes Led Pestañas Luminoso Falso Pestañas Para Partido '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0:5][\"title\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores=8):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text,nlp):\n",
    "    s = []\n",
    "    for tok in nlp.tokenizer(text):\n",
    "        if tok.is_alpha and not (tok.is_digit or tok.is_stop or len(tok.text) == 1):\n",
    "            if not tok.is_ascii:\n",
    "                tok = ''.join(c for c in unicodedata.normalize('NFD', tok.text.lower()) if unicodedata.category(c) != 'Mn')\n",
    "                s.append(tok)\n",
    "            else:\n",
    "                s.append(tok.text.lower())\n",
    "    s = ' '.join(s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_es = Spanish()\n",
    "for text in data_train[0:5][\"title\"].values:\n",
    "    print(text,\"||\", normalize_text(text, nlp_es))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    nlp_es = Spanish()\n",
    "    nlp_pt = Portuguese()\n",
    "    mask_spanish    = df[\"language\"] == 'spanish'\n",
    "    mask_portuguese = df[\"language\"] == 'portuguese'\n",
    "    df.loc[mask_spanish, \"tokens\"] = df[\"title\"].apply(normalize_text,args=(nlp_es,))\n",
    "    df.loc[mask_portuguese, \"tokens\"] = df[\"title\"].apply(normalize_text,args=(nlp_pt,))\n",
    "    df[\"label\"] = df[\"category\"].apply(lambda x: '__label__'+ x)\n",
    "    return df[[\"label\",\"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(df):\n",
    "    nlp_es = Spanish()\n",
    "    nlp_pt = Portuguese()\n",
    "    mask_spanish    = df[\"language\"] == 'spanish'\n",
    "    mask_portuguese = df[\"language\"] == 'portuguese'\n",
    "    df.loc[mask_spanish, \"tokens\"] = df[\"title\"].apply(normalize_text,args=(nlp_es,))\n",
    "    df.loc[mask_portuguese, \"tokens\"] = df[\"title\"].apply(normalize_text,args=(nlp_pt,))\n",
    "    return df[[\"id\",\"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fasttext_split_files(train_df, test_df):\n",
    "    # train and validation set files\n",
    "    train = parallelize_dataframe(train_df, preprocess)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train[\"tokens\"], train[\"label\"], test_size=0.05, random_state=42, stratify=train[\"label\"])\n",
    "    train_fasttext = pd.concat([y_train,X_train], axis=1)\n",
    "    val_fasttext = pd.concat([y_val,X_val], axis=1)\n",
    "    train_fasttext.to_csv('../data/small/train_fasttext_norm.csv',index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
    "    val_fasttext.to_csv('../data/small/val_fasttext_norm.csv',index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")   \n",
    "    \n",
    "    #test set file\n",
    "    test = parallelize_dataframe(test_df, preprocess_test)\n",
    "    test[\"tokens\"].to_csv(\"../data/small/test_fasttext_norm.txt\",index=False,header=False,line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.17 s, sys: 1.01 s, total: 9.18 s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%time create_fasttext_split_files(data_train, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 16s, sys: 1.12 s, total: 38min 17s\n",
      "Wall time: 4min 51s\n"
     ]
    }
   ],
   "source": [
    "%time model = fasttext.train_supervised(input=\"../data/small/train_fasttext_norm.csv\", epoch=5, lr=0.5, wordNgrams=2, thread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 84 ms, total: 13.1 s\n",
      "Wall time: 13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 0.82822, 0.82822)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.test('../data/small/val_fasttext_norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict('bici playera',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"../models/small/model1.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/small/test_fasttext.csv',names=['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test[\"tokens\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.Series([x[0][9:] for x in predictions[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submissions/small/submission1.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
