{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.es import Spanish\n",
    "from spacy.lang.pt import Portuguese\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from multiprocessing import  Pool\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data_train = pd.read_csv('../data/train.csv',nrows=1000000)\n",
    "data_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores=8):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    nlp_es = Spanish()\n",
    "    nlp_pt = Portuguese()\n",
    "    mask_spanish    = df[\"language\"] == 'spanish'\n",
    "    mask_portuguese = df[\"language\"] == 'portuguese'\n",
    "    df.loc[mask_spanish, \"tokens\"] = df[\"title\"].apply(lambda x: ' '.join([tok.text.lower() for tok in nlp_es.tokenizer(x) if \n",
    "                                                                          tok.is_alpha and not (tok.is_digit or tok.is_stop or len(tok.text) == 1)]))\n",
    "    df.loc[mask_portuguese, \"tokens\"] = df[\"title\"].apply(lambda x: ' '.join([tok.text.lower() for tok in nlp_pt.tokenizer(x) if\n",
    "                                                                             tok.is_alpha and not (tok.is_digit or tok.is_stop or len(tok.text) == 1)]))\n",
    "    df[\"label\"] = df[\"category\"].apply(lambda x: '__label__'+ x)\n",
    "    return df[[\"label\",\"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(df):\n",
    "    nlp_es = Spanish()\n",
    "    nlp_pt = Portuguese()\n",
    "    mask_spanish    = df[\"language\"] == 'spanish'\n",
    "    mask_portuguese = df[\"language\"] == 'portuguese'\n",
    "    df.loc[mask_spanish, \"tokens\"] = df[\"title\"].apply(lambda x: ' '.join([tok.text.lower() for tok in nlp_es.tokenizer(x) if \n",
    "                                                                          tok.is_alpha and not (tok.is_digit or tok.is_stop or len(tok.text) == 1)]))\n",
    "    df.loc[mask_portuguese, \"tokens\"] = df[\"title\"].apply(lambda x: ' '.join([tok.text.lower() for tok in nlp_pt.tokenizer(x) if\n",
    "                                                                             tok.is_alpha and not (tok.is_digit or tok.is_stop or len(tok.text) == 1)]))\n",
    "    return df[[\"id\",\"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fasttext_split_files(train_df, test_df):\n",
    "    # train and validation set files\n",
    "    train = parallelize_dataframe(train_df, preprocess)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train[\"tokens\"], train[\"label\"], test_size=0.05, random_state=42, stratify=train[\"label\"])\n",
    "    train_fasttext = pd.concat([y_train,X_train], axis=1)\n",
    "    val_fasttext = pd.concat([y_val,X_val], axis=1)\n",
    "    train_fasttext.to_csv('../data/small/train_fasttext.csv',index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
    "    val_fasttext.to_csv('../data/small/val_fasttext.csv',index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")   \n",
    "    \n",
    "    #test set file\n",
    "    test = parallelize_dataframe(test_df, preprocess_test)\n",
    "    test[\"tokens\"].to_csv(\"../data/small/test_fasttext.txt\",index=False,header=False,line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.3 s, sys: 1.32 s, total: 10.6 s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%time create_fasttext_split_files(data_train, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 14min 18s, sys: 4.97 s, total: 3h 14min 23s\n",
      "Wall time: 24min 23s\n"
     ]
    }
   ],
   "source": [
    "%time model = fasttext.train_supervised(input=\"../data/small/train_fasttext.csv\", epoch=25, lr=0.5, wordNgrams=2, thread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 60 ms, total: 13.4 s\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 0.82412, 0.82412)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.test('../data/small/val_fasttext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict('bici playera',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"../models/small/model1.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/small/test_fasttext.csv',names=['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test[\"tokens\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.Series([x[0][9:] for x in predictions[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submissions/small/submission1.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
