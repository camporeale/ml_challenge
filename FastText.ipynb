{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.es import Spanish\n",
    "from spacy.lang.pt import Portuguese\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from multiprocessing import  Pool\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data_raw = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    nlp_es = Spanish()\n",
    "    nlp_pt = Portuguese()\n",
    "    mask_spanish    = df[\"language\"] == 'spanish'\n",
    "    mask_portuguese = df[\"language\"] == 'portuguese'\n",
    "    df.loc[mask_spanish, \"tokens\"] = df[\"title\"].apply(lambda x: ' '.join([tok.text.lower() for tok in nlp_es.tokenizer(x) if \n",
    "                                                                          tok.is_alpha and not (tok.is_digit or tok.is_stop or len(tok.text) == 1)]))\n",
    "    df.loc[mask_portuguese, \"tokens\"] = df[\"title\"].apply(lambda x: ' '.join([tok.text.lower() for tok in nlp_pt.tokenizer(x) if\n",
    "                                                                             tok.is_alpha and not (tok.is_digit or tok.is_stop or len(tok.text) == 1)]))\n",
    "    df[\"label\"] = df[\"category\"].apply(lambda x: '__label__'+ x)\n",
    "    return df[[\"label\",\"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(df):\n",
    "    nlp_es = Spanish()\n",
    "    nlp_pt = Portuguese()\n",
    "    mask_spanish    = df[\"language\"] == 'spanish'\n",
    "    mask_portuguese = df[\"language\"] == 'portuguese'\n",
    "    df.loc[mask_spanish, \"tokens\"] = df[\"title\"].apply(lambda x: ' '.join([tok.text.lower() for tok in nlp_es.tokenizer(x) if \n",
    "                                                                          tok.is_alpha and not (tok.is_digit or tok.is_stop or len(tok.text) == 1)]))\n",
    "    df.loc[mask_portuguese, \"tokens\"] = df[\"title\"].apply(lambda x: ' '.join([tok.text.lower() for tok in nlp_pt.tokenizer(x) if\n",
    "                                                                             tok.is_alpha and not (tok.is_digit or tok.is_stop or len(tok.text) == 1)]))\n",
    "    return df[[\"id\",\"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores=8):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 s, sys: 15.9 s, total: 47.5 s\n",
      "Wall time: 24min 3s\n"
     ]
    }
   ],
   "source": [
    "%time train = parallelize_dataframe(data_raw, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train[\"tokens\"], train[\"label\"], test_size=0.05, random_state=42, stratify=train[\"label\"])\n",
    "\n",
    "train_fasttext = pd.concat([y_train,X_train], axis=1)\n",
    "test_fasttext = pd.concat([y_test,X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fasttext.to_csv('../data/train_fasttext.csv',index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
    "test_fasttext.to_csv('../data/test_fasttext.csv',index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(fasttext.FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 34min 25s, sys: 28.4 s, total: 1h 34min 53s\n",
      "Wall time: 12min 19s\n"
     ]
    }
   ],
   "source": [
    "%time model = fasttext.train_supervised(input=\"../data/train_fasttext.csv\", epoch=25, lr=0.5, wordNgrams=2, loss='hs', thread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 144 ms, total: 14.2 s\n",
      "Wall time: 14.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000000, 0.820198, 0.820198)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.test('../data/test_fasttext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__BICYCLES', '__label__STATIONARY_BICYCLES', '__label__SWAY_BARS'),\n",
       " array([9.99983549e-01, 1.03018981e-04, 2.20278780e-05]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('bici playera',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 243 ms, sys: 2.42 s, total: 2.67 s\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%time test = parallelize_dataframe(data_test, preprocess_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t1000000\n",
      "P@1\t0.820\n",
      "R@1\t0.820\n"
     ]
    }
   ],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('../data/test_fasttext.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"tokens\"].to_csv(\"../data/TEST.txt\",index=False,header=False,line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test[\"tokens\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[0] for x in predictions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'language'], dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_1 = pd.Series([x[0][9:] for x in predictions[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franco_camporeale/miniconda3/envs/meli/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "submission_1.to_csv(\"submission1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  DIAPER_BAGS\n",
       "1                           BABY_CHANGING_PADS\n",
       "2                    ENGINE_COOLING_FAN_MOTORS\n",
       "3         AUTOMOTIVE_SHOCK_ABSORBER_BUMP_STOPS\n",
       "4                               BABY_CAR_SEATS\n",
       "                          ...                 \n",
       "246950                     VEHICLE_BRAKE_DISCS\n",
       "246951                          WALKIE_TALKIES\n",
       "246952                             CALCULATORS\n",
       "246953                           DINING_TABLES\n",
       "246954                           WASTE_BASKETS\n",
       "Length: 246955, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
