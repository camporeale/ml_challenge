{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.es import Spanish\n",
    "from spacy.lang.pt import Portuguese\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from multiprocessing import  Pool\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import csv\n",
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data_train = pd.read_csv('../data/train.csv')\n",
    "data_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text,nlp):\n",
    "    s = []\n",
    "    for tok in nlp.tokenizer(text):\n",
    "        if tok.is_alpha and not (tok.is_digit or tok.is_stop or len(tok.text) == 1):\n",
    "            if not tok.is_ascii:\n",
    "                tok = ''.join(c for c in unicodedata.normalize('NFD', tok.text.lower()) if unicodedata.category(c) != 'Mn')\n",
    "                s.append(tok)\n",
    "            else:\n",
    "                s.append(tok.text.lower())\n",
    "    if not s:\n",
    "        return \"emptystring\"\n",
    "    else:\n",
    "        s = ' '.join(s)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'juego living cordoba capital'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_es = Spanish()\n",
    "nlp_pt = Portuguese()\n",
    "normalize_text(\"Juego de Living en Córdoba capital\", nlp_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores=8):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    nlp_es = Spanish()\n",
    "    nlp_pt = Portuguese()\n",
    "    mask_spanish    = df[\"language\"] == 'spanish'\n",
    "    mask_portuguese = df[\"language\"] == 'portuguese'\n",
    "    df.loc[mask_spanish, \"tokens\"] = df[\"title\"].apply(normalize_text,args=(nlp_es,))\n",
    "    df.loc[mask_portuguese, \"tokens\"] = df[\"title\"].apply(normalize_text,args=(nlp_pt,))\n",
    "    df[\"label\"] = df[\"category\"].apply(lambda x: '__label__'+ x)\n",
    "    return df[[\"label\",\"tokens\",\"language\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(df):\n",
    "    nlp_es = Spanish()\n",
    "    nlp_pt = Portuguese()\n",
    "    mask_spanish    = df[\"language\"] == 'spanish'\n",
    "    mask_portuguese = df[\"language\"] == 'portuguese'\n",
    "    df.loc[mask_spanish, \"tokens\"] = df[\"title\"].apply(normalize_text,args=(nlp_es,))\n",
    "    df.loc[mask_portuguese, \"tokens\"] = df[\"title\"].apply(normalize_text,args=(nlp_pt,))\n",
    "    return df[[\"id\",\"tokens\",\"language\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fasttext_split_files(train_df, test_df, outputfiles):\n",
    "    # train and validation set files\n",
    "    train = parallelize_dataframe(train_df, preprocess)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train[[\"tokens\",\"language\"]], train[\"label\"], test_size=0.05, random_state=42, stratify=train[\"label\"])\n",
    "    train_fasttext = pd.concat([y_train,X_train[\"tokens\"]], axis=1)\n",
    "    val_fasttext = pd.concat([y_val,X_val[\"tokens\"]], axis=1)\n",
    "    train_fasttext.to_csv(outputfiles[0],index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
    "    val_fasttext.to_csv(outputfiles[1],index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")   \n",
    "    \n",
    "    X_train[\"language\"].to_csv(\"../data/train_language_mapping.csv\",index=False,line_terminator='\\n')\n",
    "    X_val.to_csv(\"../data/val_language_mapping.csv\",index=False,line_terminator='\\n')\n",
    "    \n",
    "    #test set file\n",
    "    if test_df:\n",
    "        test = parallelize_dataframe(test_df, preprocess_test)\n",
    "        test[\"tokens\"].to_csv(outputfiles[2],index=False,header=False,line_terminator='\\n')\n",
    "        test[[\"id\",\"language\"]].to_csv('test_language_mappping.csv',index=False,header=False,line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 38s, sys: 21.1 s, total: 3min 59s\n",
      "Wall time: 26min 7s\n"
     ]
    }
   ],
   "source": [
    "%time create_fasttext_split_files(data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data_train[\"language\"], data_train[\"category\"], test_size=0.05, random_state=42, stratify=data_train[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franco_camporeale/miniconda3/envs/meli/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n",
      "/home/franco_camporeale/miniconda3/envs/meli/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_language_mapping = X_train\n",
    "train_language_mapping.to_csv(\"../data/train_language_mapping.csv\",index=False,line_terminator='\\n')\n",
    "val_language_mapping = X_val\n",
    "val_language_mapping.to_csv(\"../data/val_language_mapping.csv\",index=False,line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12h 55min 58s, sys: 22.4 s, total: 12h 56min 20s\n",
      "Wall time: 1h 37min 34s\n"
     ]
    }
   ],
   "source": [
    "%time model = fasttext.train_supervised(input=\"../data/train_fasttext.csv\", epoch=5, lr=0.5, wordNgrams=2, thread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 26s, sys: 1.38 s, total: 4min 28s\n",
      "Wall time: 4min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000000, 0.881847, 0.881847)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.test('../data/val_fasttext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict('bici playera',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"../models/model2.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[0] for x in predictions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model2 = fasttext.train_supervised(input=\"../data/train_fasttext.csv\", epoch=10, lr=0.5, wordNgrams=2, loss='hs', thread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model2.test('../data/test_fasttext.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model2 = fasttext.train_supervised(input=\"../data/train_fasttext.csv\", epoch=5, lr=0.5, wordNgrams=2, loss='hs', thread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model2.test('../data/test_fasttext.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model3 = fasttext.train_supervised(input=\"../data/train_fasttext.csv\", epoch=5, lr=0.8, wordNgrams=2, loss='hs', thread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model2.test('../data/test_fasttext.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model(\"../models/model_norm1.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/test_fasttext_norm.txt',names=['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.replace(np.nan, 'notitle',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 164 ms, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%time predictions = model.predict(test_data[\"tokens\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.Series([x[0][9:] for x in predictions[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submissions/submission_test.csv\",header=[\"category\"],index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models By Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>14794562</td>\n",
       "      <td>Vital Cat V43 Overweight X 750 Gr Mascota Food</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>CATS_AND_DOGS_FOODS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title label_quality  \\\n",
       "14794562  Vital Cat V43 Overweight X 750 Gr Mascota Food    unreliable   \n",
       "\n",
       "         language             category  \n",
       "14794562  spanish  CATS_AND_DOGS_FOODS  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_spanish    = data_train[\"language\"] == 'spanish'\n",
    "mask_portuguese = data_train[\"language\"] == 'portuguese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_df = data_train[data_train[\"language\"] == 'spanish']\n",
    "portuguese_df = data_train[data_train[\"language\"] == 'portuguese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_test = data_test[data_test[\"language\"] == 'spanish']\n",
    "portuguese_test = data_test[data_test[\"language\"] == 'portuguese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000 10000000\n"
     ]
    }
   ],
   "source": [
    "print(len(portuguese_df),len(spanish_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 12.1 s, total: 1min 47s\n",
      "Wall time: 12min 3s\n"
     ]
    }
   ],
   "source": [
    "%time create_fasttext_split_files(spanish_df, spanish_test, [\"../data/train_fasttext_spanish_norm.csv\",\"../data/val_fasttext_spanish_norm.csv\",\"../data/test_fasttext_spanish_norm.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 11.8 s, total: 1min 58s\n",
      "Wall time: 11min 26s\n"
     ]
    }
   ],
   "source": [
    "%time create_fasttext_split_files(portuguese_df, portuguese_test, [\"../data/train_fasttext_portuguese_norm.csv\",\"../data/val_fasttext_portuguese_norm.csv\",\"../data/test_fasttext_portuguese_norm.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[3:4][\"id\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_es = fasttext.load_model(\"../models/model_spanish_norm.bin\")\n",
    "model_pt = fasttext.load_model(\"../models/model_portuguese_norm.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__label__DIGITAL_PORTABLE_MEDIA_PLAYERS'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pt.predict(\"testing\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_es = Spanish()\n",
    "nlp_pt = Portuguese()\n",
    "from collections import defaultdict\n",
    "\n",
    "data = {\"id\": [], \"category\": []}\n",
    "\n",
    "for index, row in data_test.iterrows():\n",
    "    if row[\"language\"] == 'portuguese':\n",
    "        title = normalize_text(row[\"title\"],nlp_pt)\n",
    "        category = model_pt.predict(title)[0][0]\n",
    "    if row[\"language\"] == 'spanish':\n",
    "        title = normalize_text(row[\"title\"],nlp_es)\n",
    "        category = model_es.predict(title)[0][0]\n",
    "    data[\"id\"].append(row[\"id\"])\n",
    "    data[\"category\"].append(category[9:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submissions/submission_multiple_lang_1.csv\",header=[\"id\",\"category\"],index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model=fasttext.load_model(\"../models/model_norm1.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv(\"../data/val_fasttext_norm.csv\",nrows=200000,header=None,names=[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[\"category\"] = val_data[\"tokens\"].apply(lambda x: x.split()[0][9:])\n",
    "val_data[\"title\"] = val_data[\"tokens\"].apply(lambda x:  ' '.join(x.split()[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[\"predicted\"] = ''\n",
    "val_data[\"score\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {\"id\": [], \"tokens\": [], \"category\": [], \"predicted\": [], \"score\": []}\n",
    "\n",
    "for index, row in val_data.iterrows():\n",
    "    result = best_model.predict(row[\"tokens\"])\n",
    "    predictions[\"id\"].append(index)\n",
    "    predictions[\"tokens\"].append(row[\"tokens\"])\n",
    "    predictions[\"category\"].append(row[\"category\"])\n",
    "    predictions[\"predicted\"].append(result[0][0][9:])\n",
    "    predictions[\"score\"].append(result[1][0])\n",
    "\n",
    "prediction_data = pd.DataFrame.from_dict(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data_train[[\"title\",\"label_quality\",\"language\"]], data_train[\"category\"], test_size=0.05, random_state=42, stratify=data_train[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_data[\"original_title\"] = X_val[:200000][\"title\"].values\n",
    "#prediction_data[\"label_quality\"] = X_val[:200000][\"label_quality\"].values\n",
    "prediction_data[\"language\"] = X_val[:200000][\"language\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data.rename(columns={'title':'tokens'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_data = prediction_data[prediction_data[\"category\"] != prediction_data[\"predicted\"]][[\"id\",\"original_title\",\"tokens\",\"category\",\"predicted\",\"label_quality\",\"language\",\"score\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1556"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors_data[\"category\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spanish       0.507781\n",
       "portuguese    0.492219\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_data[\"language\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_data.head(100)[[\"original_title\",\"tokens\",\"category\",\"predicted\",\"label_quality\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unreliable    0.940788\n",
       "reliable      0.059212\n",
       "Name: label_quality, dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"label_quality\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unreliable    0.960193\n",
       "reliable      0.039807\n",
       "Name: label_quality, dtype: float64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_data[\"label_quality\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>tokens</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>120636</td>\n",
       "      <td>Coxim Axial Bucha Pivo Rolamento Da Roda  Fies...</td>\n",
       "      <td>coxim axial bucha pivo rolamento da roda fiest...</td>\n",
       "      <td>SUSPENSION_BALL_JOINTS</td>\n",
       "      <td>SHOCK_MOUNT_INSOLATORS</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0.363446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186122</td>\n",
       "      <td>Correntinha + Pingente Folheado A Ouro 46 Cm</td>\n",
       "      <td>correntinha pingente folheado ouro cm</td>\n",
       "      <td>NECKLACES</td>\n",
       "      <td>CHARMS_AND_MEDALS</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0.939457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4115</td>\n",
       "      <td>Pés De Mesa  / Aparador ( Monte Facil )</td>\n",
       "      <td>pes de mesa aparador monte facil</td>\n",
       "      <td>STOOLS</td>\n",
       "      <td>TV_AND_MONITOR_MOUNTS</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0.305697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60545</td>\n",
       "      <td>Tubo Do Escapamento Motorm Sailor Yamaha 15hp 2t</td>\n",
       "      <td>tubo do escapamento motorm sailor yamaha</td>\n",
       "      <td>MEMORY_CARDS</td>\n",
       "      <td>MOTORCYCLE_EXHAUSTS</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0.830055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158944</td>\n",
       "      <td>Lote X 10 Codos Tigre 25 Mm A 45 Grados</td>\n",
       "      <td>lote codos tigre mm grados</td>\n",
       "      <td>CONNECTING_COUPLERS</td>\n",
       "      <td>PIPES_AND_TUBES</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0.845858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8472</td>\n",
       "      <td>Eixo Bmw 116i - 2014 - Sucata Peças</td>\n",
       "      <td>eixo bmw sucata pecas</td>\n",
       "      <td>AUTOMOTIVE_FRONT_BUMPERS</td>\n",
       "      <td>REAR_WHEEL_HUBS_BEARING_ASSEMBLY</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0.996451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128025</td>\n",
       "      <td>Fix-30p-d8 Baja Puntuación De La Pantalla De L...</td>\n",
       "      <td>baja puntuacion de la pantalla de la linea de</td>\n",
       "      <td>LCD_DISPLAYS</td>\n",
       "      <td>LAPTOP_LCD_SCREENS</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0.043920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39842</td>\n",
       "      <td>Niebla Fabricante 12 Led Fogger Niebla Fuente ...</td>\n",
       "      <td>niebla fabricante led fogger niebla fuente agu...</td>\n",
       "      <td>DEHUMIDIFIERS</td>\n",
       "      <td>INSECTICIDES</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0.069133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44770</td>\n",
       "      <td>Borracha Do Bojo Do Farol Olho De Boi E Parala...</td>\n",
       "      <td>borracha do bojo do farol olho de boi paralama...</td>\n",
       "      <td>AUTOMOTIVE_EMBLEMS</td>\n",
       "      <td>AUTOMOTIVE_WEATHERSTRIPS</td>\n",
       "      <td>reliable</td>\n",
       "      <td>0.596206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35632</td>\n",
       "      <td>Valv Agulha Weber 40</td>\n",
       "      <td>valv agulha weber</td>\n",
       "      <td>TURNTABLE_NEEDLES</td>\n",
       "      <td>CAR_CARBURETORS</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0.961341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           original_title  \\\n",
       "120636  Coxim Axial Bucha Pivo Rolamento Da Roda  Fies...   \n",
       "186122       Correntinha + Pingente Folheado A Ouro 46 Cm   \n",
       "4115              Pés De Mesa  / Aparador ( Monte Facil )   \n",
       "60545    Tubo Do Escapamento Motorm Sailor Yamaha 15hp 2t   \n",
       "158944            Lote X 10 Codos Tigre 25 Mm A 45 Grados   \n",
       "8472                  Eixo Bmw 116i - 2014 - Sucata Peças   \n",
       "128025  Fix-30p-d8 Baja Puntuación De La Pantalla De L...   \n",
       "39842   Niebla Fabricante 12 Led Fogger Niebla Fuente ...   \n",
       "44770   Borracha Do Bojo Do Farol Olho De Boi E Parala...   \n",
       "35632                                Valv Agulha Weber 40   \n",
       "\n",
       "                                                   tokens  \\\n",
       "120636  coxim axial bucha pivo rolamento da roda fiest...   \n",
       "186122              correntinha pingente folheado ouro cm   \n",
       "4115                     pes de mesa aparador monte facil   \n",
       "60545            tubo do escapamento motorm sailor yamaha   \n",
       "158944                         lote codos tigre mm grados   \n",
       "8472                                eixo bmw sucata pecas   \n",
       "128025      baja puntuacion de la pantalla de la linea de   \n",
       "39842   niebla fabricante led fogger niebla fuente agu...   \n",
       "44770   borracha do bojo do farol olho de boi paralama...   \n",
       "35632                                   valv agulha weber   \n",
       "\n",
       "                        category                         predicted  \\\n",
       "120636    SUSPENSION_BALL_JOINTS            SHOCK_MOUNT_INSOLATORS   \n",
       "186122                 NECKLACES                 CHARMS_AND_MEDALS   \n",
       "4115                      STOOLS             TV_AND_MONITOR_MOUNTS   \n",
       "60545               MEMORY_CARDS               MOTORCYCLE_EXHAUSTS   \n",
       "158944       CONNECTING_COUPLERS                   PIPES_AND_TUBES   \n",
       "8472    AUTOMOTIVE_FRONT_BUMPERS  REAR_WHEEL_HUBS_BEARING_ASSEMBLY   \n",
       "128025              LCD_DISPLAYS                LAPTOP_LCD_SCREENS   \n",
       "39842              DEHUMIDIFIERS                      INSECTICIDES   \n",
       "44770         AUTOMOTIVE_EMBLEMS          AUTOMOTIVE_WEATHERSTRIPS   \n",
       "35632          TURNTABLE_NEEDLES                   CAR_CARBURETORS   \n",
       "\n",
       "       label_quality     score  \n",
       "120636    unreliable  0.363446  \n",
       "186122    unreliable  0.939457  \n",
       "4115      unreliable  0.305697  \n",
       "60545     unreliable  0.830055  \n",
       "158944    unreliable  0.845858  \n",
       "8472      unreliable  0.996451  \n",
       "128025    unreliable  0.043920  \n",
       "39842     unreliable  0.069133  \n",
       "44770       reliable  0.596206  \n",
       "35632     unreliable  0.961341  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_data.sample(10)[[\"original_title\",\"tokens\",\"category\",\"predicted\",\"label_quality\",\"score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliable Labels Oversampling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlabel = data_train[data_train[\"label_quality\"] == 'reliable'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlabel = data_train[data_train[\"label_quality\"] == 'unreliable'].sample(1184245).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([rlabel,urlabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 s, sys: 9.14 s, total: 31.2 s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%time create_fasttext_split_files(data, None, [\"../data/train_fasttext_reliable_norm.csv\",\"../data/val_fasttext_reliable_norm.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model = fasttext.train_supervised(input=\"../data/train_fasttext_reliable_norm.csv\", epoch=5, lr=0.5, wordNgrams=2, thread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del urlabel\n",
    "del rlabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "voted = {'id':[1,2,3,4], \n",
    "         1: ['PANTS','SHOES','POSTER','TOYS'], \n",
    "         2: ['SHORTS','CLASSIC SHOES','POSTER','TOYS'], \n",
    "         3: ['SHORTS','SHOES','CHILD POSTER','TOYS'],\n",
    "         4: ['PANTS','CLASSIC SHOES','POSTER','TOYS'], \n",
    "         5: ['SHORTS','OLD SHOES','POSTER','SMALL TOYS']}\n",
    "testing = pd.DataFrame.from_dict(voted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PANTS</td>\n",
       "      <td>SHORTS</td>\n",
       "      <td>SHORTS</td>\n",
       "      <td>PANTS</td>\n",
       "      <td>SHORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>CLASSIC SHOES</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>CLASSIC SHOES</td>\n",
       "      <td>OLD SHOES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>POSTER</td>\n",
       "      <td>POSTER</td>\n",
       "      <td>CHILD POSTER</td>\n",
       "      <td>POSTER</td>\n",
       "      <td>POSTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>TOYS</td>\n",
       "      <td>TOYS</td>\n",
       "      <td>TOYS</td>\n",
       "      <td>TOYS</td>\n",
       "      <td>SMALL TOYS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       1              2             3              4           5\n",
       "0   1   PANTS         SHORTS        SHORTS          PANTS      SHORTS\n",
       "1   2   SHOES  CLASSIC SHOES         SHOES  CLASSIC SHOES   OLD SHOES\n",
       "2   3  POSTER         POSTER  CHILD POSTER         POSTER      POSTER\n",
       "3   4    TOYS           TOYS          TOYS           TOYS  SMALL TOYS"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHORTS\n",
      "SHOES\n",
      "POSTER\n",
      "TOYS\n"
     ]
    }
   ],
   "source": [
    "for index, row in testing.iloc[:,1:].iterrows():\n",
    "    print(row.value_counts().index[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_ensemble(modelfiles, datafile):\n",
    "    print(\"Loading data file...\")\n",
    "    data = pd.read_csv(datafile,names=['title'])\n",
    "    language_mapping = pd.read_csv('../data/test_language_mapping.csv')\n",
    "    results_df = pd.DataFrame(data.index.values, columns = ['id']) \n",
    "    voted_results = {\"id\": [], \"category\": []}\n",
    "\n",
    "    print(\"Loading models and predicting Test...\")\n",
    "    for i, file in enumerate(modelfiles):\n",
    "        print(\"Loading model file \", file, '...')\n",
    "        if isinstance(file, dict):\n",
    "            # Here we predict combining models for each language\n",
    "            predictions = []\n",
    "            test_language = pd.concat([data,language_mapping['language']],axis=1)\n",
    "            model_sp = fasttext.load_model(file[\"spanish\"])\n",
    "            model_pt = fasttext.load_model(file[\"portuguese\"])\n",
    "            print(\"Running predict on test set...\")\n",
    "            for index, row in test_language.iterrows():\n",
    "                if row[\"language\"] == 'spanish':\n",
    "                    category = model_sp.predict(row[\"title\"])[0][0]\n",
    "                if row[\"language\"] == 'portuguese':\n",
    "                    category = model_pt.predict(row[\"title\"])[0][0]\n",
    "                predictions.append(category[9:])\n",
    "            results_df[i] = pd.Series(predictions)\n",
    "        else:            \n",
    "            model = fasttext.load_model(file)\n",
    "            print(\"Running predict on test set...\")\n",
    "            #print(test_data[\"tokens\"].values.tolist()[0:10])\n",
    "            predictions = model.predict(data[\"title\"].values.tolist())\n",
    "            results_df[i] = pd.Series([x[0][9:] for x in predictions[0]])\n",
    "        print(\"Predict finished for model \", file)\n",
    "    print(\"Finished loading models and making predictions for test set\")\n",
    "  \n",
    "    print(\"Counting votes and defining prediction...\")         \n",
    "    for index, row in results_df.iloc[:,1:].iterrows():\n",
    "        voted_results[\"id\"].append(index)\n",
    "        voted_results[\"category\"].append(row.value_counts().index[0])\n",
    "    \n",
    "    voted_results_df = pd.DataFrame.from_dict(voted_results)\n",
    "    print(\"Finished\")\n",
    "    return voted_results_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = [{\"spanish\": \"../models/model_spanish_norm.bin\",\"portuguese\":\"../models/model_portuguese_norm.bin\"},\n",
    "               \"../models/model_norm2.bin\",\"../models/model_norm1.bin\",\"../models/model_reliable_norm1.bin\", \"../models/model_norm3.bin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data file...\n",
      "Loading models and predicting Test...\n",
      "Loading model file  {'spanish': '../models/model_spanish_norm.bin', 'portuguese': '../models/model_portuguese_norm.bin'} ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predict on test set...\n",
      "Predict finished for model  {'spanish': '../models/model_spanish_norm.bin', 'portuguese': '../models/model_portuguese_norm.bin'}\n",
      "Loading model file  ../models/model_norm2.bin ...\n",
      "Running predict on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict finished for model  ../models/model_norm2.bin\n",
      "Loading model file  ../models/model_norm1.bin ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predict on test set...\n",
      "Predict finished for model  ../models/model_norm1.bin\n",
      "Loading model file  ../models/model_reliable_norm1.bin ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predict on test set...\n",
      "Predict finished for model  ../models/model_reliable_norm1.bin\n",
      "Loading model file  ../models/model_norm3.bin ...\n",
      "Running predict on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict finished for model  ../models/model_norm3.bin\n",
      "Finished loading models and making predictions for test set\n",
      "Counting votes and defining prediction...\n",
      "Finished\n",
      "CPU times: user 10min 42s, sys: 18.6 s, total: 11min\n",
      "Wall time: 10min 55s\n"
     ]
    }
   ],
   "source": [
    "%time results = predict_test_ensemble(model_files,'../data/test_fasttext_norm.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY_CHANGING_PADS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENGINE_COOLING_FAN_MOTORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>AUTOMOTIVE_SHOCK_ABSORBER_BUMP_STOPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>BABY_CAR_SEATS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246950</td>\n",
       "      <td>246950</td>\n",
       "      <td>VEHICLE_BRAKE_DISCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246951</td>\n",
       "      <td>246951</td>\n",
       "      <td>WALKIE_TALKIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246952</td>\n",
       "      <td>246952</td>\n",
       "      <td>CALCULATORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246953</td>\n",
       "      <td>246953</td>\n",
       "      <td>DINING_SETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246954</td>\n",
       "      <td>246954</td>\n",
       "      <td>WASTE_BASKETS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246955 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                              category\n",
       "0            0                           DIAPER_BAGS\n",
       "1            1                    BABY_CHANGING_PADS\n",
       "2            2             ENGINE_COOLING_FAN_MOTORS\n",
       "3            3  AUTOMOTIVE_SHOCK_ABSORBER_BUMP_STOPS\n",
       "4            4                        BABY_CAR_SEATS\n",
       "...        ...                                   ...\n",
       "246950  246950                   VEHICLE_BRAKE_DISCS\n",
       "246951  246951                        WALKIE_TALKIES\n",
       "246952  246952                           CALCULATORS\n",
       "246953  246953                           DINING_SETS\n",
       "246954  246954                         WASTE_BASKETS\n",
       "\n",
       "[246955 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"./submissions/submission_ensemble_3.csv\",header=[\"id\",\"category\"],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('../data/val_fasttext_norm.csv',header=None,names=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data['title'] = val_data['title'].apply(lambda x: ' '.join(x.split()[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_val(model):\n",
    "    val_data = pd.read_csv('../data/val_fasttext_norm.csv',header=None,names=['title'])\n",
    "    val_data['title'] = val_data['title'].apply(lambda x: ' '.join(x.split()[1:]))\n",
    "    \n",
    "    print(\"Loading model file \", model, '...')\n",
    "    if isinstance(model, dict):\n",
    "        # Here we predict combining models for each language\n",
    "        predictions = []\n",
    "        language_mapping = pd.read_csv('../data/val_language_mapping.csv',names=[\"language\"])\n",
    "        val_language = pd.concat([val_data,language_mapping['language']],axis=1)\n",
    "        model_sp = fasttext.load_model(model[\"spanish\"])\n",
    "        model_pt = fasttext.load_model(model[\"portuguese\"])\n",
    "        print(\"Running predict on val set...\")\n",
    "        for index, row in val_language.iterrows():\n",
    "            if row[\"language\"] == 'spanish':\n",
    "                category = model_sp.predict(row[\"title\"])[0][0]\n",
    "            if row[\"language\"] == 'portuguese':\n",
    "                category = model_pt.predict(row[\"title\"])[0][0]\n",
    "            predictions.append(category[9:])\n",
    "        print(\"Predict finished for model \", model)\n",
    "        return pd.Series(predictions)\n",
    "\n",
    "    else:            \n",
    "        model = fasttext.load_model(model)\n",
    "        print(\"Running predict on val set...\")\n",
    "        predictions = model.predict(val_data[\"title\"].values.tolist())\n",
    "        print(\"Predict finished for model \", model)\n",
    "        return pd.Series([x[0][9:] for x in predictions[0]])\n",
    "\n",
    "            \n",
    "def parallel_models_get_val_results(model_files, n_cores=5):\n",
    "    results = Parallel(n_jobs=n_cores)(delayed(run_model_val)(model) for model in model_files)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 826 ms, sys: 327 ms, total: 1.15 s\n",
      "Wall time: 11min 52s\n"
     ]
    }
   ],
   "source": [
    "model_files = [{\"spanish\": \"../models/model_spanish_norm200.bin\",\"portuguese\":\"../models/model_portuguese_norm200.bin\"},\n",
    "               \"../models/model_norm1.bin\",\"../models/model_norm2.bin\",\"../models/model_norm3.bin\",\"../models/model_reliable_norm1.bin\"]\n",
    "\n",
    "%time results = parallel_models_get_val_results(model_files, n_cores=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([x for x in results], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TENNIS_BAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ORTHOTICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PUPPETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>AUDIO_INTERFACES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EPILATORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999995</td>\n",
       "      <td>999995</td>\n",
       "      <td>COMPUTER_PROCESSORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999996</td>\n",
       "      <td>999996</td>\n",
       "      <td>LIP_BALMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999997</td>\n",
       "      <td>999997</td>\n",
       "      <td>CRIBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999998</td>\n",
       "      <td>999998</td>\n",
       "      <td>AUTOMOTIVE_SPRING_SUSPENSIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999999</td>\n",
       "      <td>999999</td>\n",
       "      <td>FABRICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                       category\n",
       "0            0                    TENNIS_BAGS\n",
       "1            1                      ORTHOTICS\n",
       "2            2                        PUPPETS\n",
       "3            3               AUDIO_INTERFACES\n",
       "4            4                      EPILATORS\n",
       "...        ...                            ...\n",
       "999995  999995            COMPUTER_PROCESSORS\n",
       "999996  999996                      LIP_BALMS\n",
       "999997  999997                          CRIBS\n",
       "999998  999998  AUTOMOTIVE_SPRING_SUSPENSIONS\n",
       "999999  999999                        FABRICS\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voted_results = {\"id\": [], \"category\": []}\n",
    "\n",
    "for index, row in results_df.iloc[:,1:].iterrows():\n",
    "    voted_results[\"id\"].append(index)\n",
    "    voted_results[\"category\"].append(row.value_counts().index[0])\n",
    "\n",
    "voted_results_df = pd.DataFrame.from_dict(voted_results)\n",
    "voted_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('../data/val_fasttext_norm.csv',header=None,names=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data['category'] = val_data['title'].apply(lambda x: x.split()[0][9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"category\"] = val_data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>kit maternidade bolsa mala baby bebe vinho menina</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>trocador de fraldas fisher price feminino rosa...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>motor ventoinha fiat idea palio</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>amortecedor mola batente dir new civic</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>cadeirinha de carro bebe princesa princess kgs</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>cabo freio mao tras direito vw up cod</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>mini pc dell optiplex atom gb ram ssd gb wifi</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>kit bi xenon lampada</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>protetor pe botinha kickboxing karate taekwond...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>disco rigido externo western digital elements tb</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>picadora de carne fineschi legitima</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title    language\n",
       "0   kit maternidade bolsa mala baby bebe vinho menina  portuguese\n",
       "1   trocador de fraldas fisher price feminino rosa...  portuguese\n",
       "2                     motor ventoinha fiat idea palio  portuguese\n",
       "3              amortecedor mola batente dir new civic  portuguese\n",
       "4      cadeirinha de carro bebe princesa princess kgs  portuguese\n",
       "5               cabo freio mao tras direito vw up cod  portuguese\n",
       "6       mini pc dell optiplex atom gb ram ssd gb wifi  portuguese\n",
       "7                                kit bi xenon lampada  portuguese\n",
       "8   protetor pe botinha kickboxing karate taekwond...  portuguese\n",
       "9    disco rigido externo western digital elements tb     spanish\n",
       "10                picadora de carne fineschi legitima     spanish"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('../data/test_fasttext_norm.csv',header=None,names=['title'])\n",
    "test_data['title'] = test_data['title'].apply(lambda x: ' '.join(x.split()))\n",
    "language_mapping = pd.read_csv('../data/test_language_mapping.csv',names=[\"language\"])\n",
    "test_language = pd.concat([test_data,language_mapping['language']],axis=1)\n",
    "test_language.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_test(model):\n",
    "    test_data = pd.read_csv('../data/test_fasttext_norm.csv',header=None,names=['title'])\n",
    "    test_data['title'] = test_data['title'].apply(lambda x: ' '.join(x.split()))\n",
    "    test_data.head(10).to_csv('rv.csv')\n",
    "    print(\"Loading model file \", model, '...')\n",
    "    if isinstance(model, dict):\n",
    "        # Here we predict combining models for each language\n",
    "        predictions = []\n",
    "        language_mapping = pd.read_csv('../data/test_language_mapping.csv',names=[\"language\"])\n",
    "        test_language = pd.concat([test_data,language_mapping['language']],axis=1)\n",
    "        model_sp = fasttext.load_model(model[\"spanish\"])\n",
    "        model_pt = fasttext.load_model(model[\"portuguese\"])\n",
    "        print(\"Running predict on test set...\")\n",
    "        for index, row in test_language.iterrows():\n",
    "            if row[\"language\"] == 'spanish':\n",
    "                category = model_sp.predict(row[\"title\"])[0][0]\n",
    "            if row[\"language\"] == 'portuguese':\n",
    "                category = model_pt.predict(row[\"title\"])[0][0]\n",
    "            predictions.append(category[9:])\n",
    "        print(\"Predict finished for model \", model)\n",
    "        return pd.Series(predictions)\n",
    "\n",
    "    else:            \n",
    "        model = fasttext.load_model(model)\n",
    "        print(\"Running predict on test set...\")\n",
    "        predictions = model.predict(test_data[\"title\"].values.tolist())\n",
    "        print(\"Predict finished for model \", model)\n",
    "        return pd.Series([x[0][9:] for x in predictions[0]])\n",
    "\n",
    "            \n",
    "def parallel_models_get_test_results(model_files, n_cores=5):\n",
    "    results = Parallel(n_jobs=n_cores)(delayed(run_model_test)(model) for model in model_files)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 338 ms, sys: 884 ms, total: 1.22 s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "model_files = [{\"spanish\": \"../models/model_spanish_norm200.bin\",\"portuguese\":\"../models/model_portuguese_norm200.bin\"},\n",
    "               \"../models/model_norm1.bin\",\"../models/model_norm2.bin\",\"../models/model_norm3.bin\",\"../models/model_reliable_norm1.bin\"]\n",
    "\n",
    "%time results = parallel_models_get_test_results(model_files, n_cores=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(results):\n",
    "    voted_results = {\"id\": [], \"category\": []}\n",
    "    results_df = pd.concat([x for x in results], axis=1)\n",
    "    for index, row in results_df.iloc[:,1:].iterrows():\n",
    "        voted_results[\"id\"].append(index)\n",
    "        voted_results[\"category\"].append(row.value_counts().index[0])\n",
    "\n",
    "    voted_results_df = pd.DataFrame.from_dict(voted_results)\n",
    "    return voted_results_df\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 16s, sys: 962 ms, total: 3min 17s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%time voted_results_df = calculate_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_results_df.to_csv(\"./submissions/submission_ensemble_5.csv\",header=[\"id\",\"category\"],index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skift import FirstColFtClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FirstColFtClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m = fasttext.load_model(\"../oldmodels/model_norm1.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__PAINT_BRUSHES',), array([0.157928]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'PET_COLLARS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-828776484b94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'woof'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/meli/lib/python3.7/site-packages/skift/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    159\u001b[0m         return np.array([\n\u001b[1;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         ], dtype=np.float_)\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/meli/lib/python3.7/site-packages/skift/core.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    159\u001b[0m         return np.array([\n\u001b[1;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         ], dtype=np.float_)\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/meli/lib/python3.7/site-packages/skift/core.py\u001b[0m in \u001b[0;36m_clean_label\u001b[0;34m(ft_label)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clean_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'PET_COLLARS'"
     ]
    }
   ],
   "source": [
    "model.predict([['woof']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
